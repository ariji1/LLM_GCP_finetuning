{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b841970-c07e-4575-bc5a-40597cc2583a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.15.1 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet keras-nlp\n",
    "%pip install --upgrade --quiet keras\n",
    "\n",
    "# Hugging Face Transformers\n",
    "%pip install --upgrade --quiet accelerate sentencepiece transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b7d800-62ae-43ce-bda1-34953e38b885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c9c7afd9954943aacd881c3766ca37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0d8a125-6f63-46cb-b750-5d581c477696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID='sbx-196865-genaift-ds-ccd784e6'\n"
     ]
    }
   ],
   "source": [
    "res = !gcloud config get core/project\n",
    "PROJECT_ID = res[0]\n",
    "\n",
    "print(f\"{PROJECT_ID=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b2600c-a676-409e-b7ce-567352adfb11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ The bucket exists\n"
     ]
    }
   ],
   "source": [
    "# Define a bucket related to your project\n",
    "BUCKET_URI = f\"gs://gemma-{PROJECT_ID}-unique\"\n",
    "# Or use an existing one\n",
    "# BUCKET_URI = \"gs://\"  # @param {type:\"string\"}\n",
    "\n",
    "res = !gcloud storage buckets describe $BUCKET_URI --format \"value(name)\"\n",
    "if len(res) == 1 and \"ERROR\" not in res[0]:\n",
    "    print(\"✔️ The bucket exists\")\n",
    "else:\n",
    "    print(\"⚙️ Creating the bucket…\")\n",
    "    !gcloud storage buckets create $BUCKET_URI --project $PROJECT_ID --location $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a48964-b665-4097-bcb2-11f3ee6b83fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import locale\n",
    "\n",
    "import keras\n",
    "import keras_nlp\n",
    "import torch\n",
    "import transformers\n",
    "from google.cloud import aiplatform\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6d62336-4808-424a-82d9-2c71774e174a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"gemma_2b_en\"\n",
    "# MODEL_NAME = \"gemma_instruct_2b_en\"\n",
    "MODEL_NAME = \"gemma_7b_en\"\n",
    "# MODEL_NAME = \"gemma_instruct_7b_en\"\n",
    "\n",
    "# Deduce model size from name format: \"gemma[_instruct]_{2b,7b}_en\"\n",
    "MODEL_SIZE = MODEL_NAME.split(\"_\")[-2]\n",
    "assert MODEL_SIZE in (\"2b\", \"7b\")\n",
    "\n",
    "# Dataset\n",
    "DATASET_NAME = \"databricks-dolly-15k\"\n",
    "DATASET_PATH = f\"{DATASET_NAME}.jsonl\"\n",
    "DATASET_URL = f\"https://huggingface.co/datasets/databricks/{DATASET_NAME}/resolve/main/{DATASET_PATH}\"\n",
    "\n",
    "# Finetuned model\n",
    "FINETUNED_MODEL_DIR = '19865_finetuned_models/gemma-keras-lora-train_20240308_200536'\n",
    "# FINETUNED_MODEL_DIR = f\"./{MODEL_NAME}_{DATASET_NAME}\"\n",
    "# FINETUNED_WEIGHTS_PATH = f\"{FINETUNED_MODEL_DIR}/model.weights.h5\"\n",
    "FINETUNED_WEIGHTS_PATH = f\"{FINETUNED_MODEL_DIR}/fine_tuned.weights.h5\"\n",
    "FINETUNED_VOCAB_PATH = f\"{FINETUNED_MODEL_DIR}/vocabulary.spm\"\n",
    "\n",
    "# Converted model\n",
    "HUGGINGFACE_MODEL_DIR = f\"./{MODEL_NAME}_huggingface\"\n",
    "\n",
    "# Deployed model\n",
    "DEPLOYED_MODEL_URI = f\"{BUCKET_URI}/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b8b147d-144d-43ec-8d1d-a278f6ee5a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()\n",
    "cuda.select_device(device.id)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c020b471-0abe-43c6-b3d2-4be0e02e882d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/jupyter/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dabf4dcf-073d-40b6-9405-a9d3e196f26e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-09 09:33:20.738016: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-09 09:33:20.738098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-09 09:33:20.739908: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-09 09:33:20.749453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 09:33:26.759111: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-09 09:33:26.763876: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-09 09:33:26.766940: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "\n",
      "-> Loading Keras weights from file `19865_finetuned_models/gemma-keras-lora-train_20240308_200536/fine_tuned.weights.h5`...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/config.json...\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/kagglehub/exceptions.py\", line 49, in kaggle_api_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/export_gemma_to_hf.py\", line 349, in <module>\n",
      "    app.run(main)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/jupyter/export_gemma_to_hf.py\", line 338, in main\n",
      "    convert_checkpoints(\n",
      "  File \"/home/jupyter/export_gemma_to_hf.py\", line 142, in convert_checkpoints\n",
      "    keras_nlp_model = keras_nlp.models.GemmaCausalLM.from_preset(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_nlp/src/models/task.py\", line 258, in from_preset\n",
      "    return super(cls, calling_cls).from_preset(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_nlp/src/models/task.py\", line 258, in from_preset\n",
      "    return super(cls, calling_cls).from_preset(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_nlp/src/models/task.py\", line 219, in from_preset\n",
      "    preset_cls = check_preset_class(preset, (cls, cls.backbone_cls))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_nlp/src/utils/preset_utils.py\", line 203, in check_preset_class\n",
      "    config_path = get_file(preset, config_file)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras_nlp/src/utils/preset_utils.py\", line 54, in get_file\n",
      "    return kagglehub.model_download(kaggle_handle, path)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/kagglehub/models.py\", line 25, in model_download\n",
      "    return registry.model_resolver(h, path, force_download=force_download)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/kagglehub/registry.py\", line 23, in __call__\n",
      "    return impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/kagglehub/http_resolver.py\", line 46, in __call__\n",
      "    api_client.download_file(url_path + \"/\" + path, out_path, h)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/kagglehub/clients.py\", line 136, in download_file\n",
      "    kaggle_api_raise_for_status(response, resource_handle)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/kagglehub/exceptions.py\", line 71, in kaggle_api_raise_for_status\n",
      "    raise KaggleApiHTTPError(message, response=response) from e\n",
      "kagglehub.exceptions.KaggleApiHTTPError: 403 Client Error.\n",
      "\n",
      "You don't have permission to access resource at URL: https://www.kaggle.com/models/keras/gemma/frameworks/keras/variations/gemma_7b_en/versions/2\n",
      "Please make sure you are authenticated if you are trying to access a private resource or a resource requiring consent.\n"
     ]
    }
   ],
   "source": [
    "# Download the conversion script from KerasNLP tools\n",
    "!wget -nv -nc https://raw.githubusercontent.com/keras-team/keras-nlp/master/tools/gemma/export_gemma_to_hf.py\n",
    "\n",
    "# Run the conversion script\n",
    "# Note: it uses the PyTorch backend of Keras (hence the KERAS_BACKEND env variable)\n",
    "!KERAS_BACKEND=torch python export_gemma_to_hf.py \\\n",
    "    --weights_file $FINETUNED_WEIGHTS_PATH \\\n",
    "    --size $MODEL_SIZE \\\n",
    "    --vocab_path $FINETUNED_VOCAB_PATH \\\n",
    "    --output_dir $HUGGINGFACE_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81459661-530c-4eac-9cb9-440617030177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL Flags parsing error: Unknown command line flag 'f'\n",
      "Pass --helpshort or --helpfull to see help on flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/absl/app.py:156\u001b[0m, in \u001b[0;36mparse_flags_with_usage\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFLAGS\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/absl/flags/_flagvalues.py:685\u001b[0m, in \u001b[0;36mFlagValues.__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    684\u001b[0m   suggestions \u001b[38;5;241m=\u001b[39m _helpers\u001b[38;5;241m.\u001b[39mget_flag_suggestions(name, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 685\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _exceptions\u001b[38;5;241m.\u001b[39mUnrecognizedFlagError(\n\u001b[1;32m    686\u001b[0m       name, value, suggestions\u001b[38;5;241m=\u001b[39msuggestions)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmark_as_parsed()\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 349\u001b[0m\n\u001b[1;32m    348\u001b[0m flags\u001b[38;5;241m.\u001b[39mmark_flag_as_required(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/absl/app.py:300\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[43m_run_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m      \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflags_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m _init_callbacks:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/absl/app.py:369\u001b[0m, in \u001b[0;36m_run_init\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    368\u001b[0m logging\u001b[38;5;241m.\u001b[39muse_absl_handler()\n\u001b[0;32m--> 369\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43m_register_and_parse_flags_with_usage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43margv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflags_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m faulthandler:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/absl/app.py:216\u001b[0m, in \u001b[0;36m_register_and_parse_flags_with_usage\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    215\u001b[0m original_argv \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;28;01mif\u001b[39;00m argv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m argv\n\u001b[0;32m--> 216\u001b[0m args_to_main \u001b[38;5;241m=\u001b[39m \u001b[43mflags_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_argv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m FLAGS\u001b[38;5;241m.\u001b[39mis_parsed():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/absl/app.py:166\u001b[0m, in \u001b[0;36mparse_flags_with_usage\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    165\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPass --helpshort or --helpfull to see help on flags.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "# Copyright 2024 The KerasNLP Authors\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import contextlib\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import keras_nlp\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "\"\"\"\n",
    "Sample usage:\n",
    "\n",
    "For converting a keras model to HuggingFace format using a custom or fine-tuned\n",
    "checkpoint from Keras, make sure to pass the path for the Keras weights file\n",
    "(ending in `.weights.h5`), the model size (`2b` or `7b`), and the tokenizer\n",
    "vocabulary file (`.spm`, `.model`, or equivalent) to\n",
    "`--weights_file`, `--size`, and `--vocab_path`, respectively.\n",
    "\n",
    "Optionally, you can specify the output directory\n",
    "for the converted model at `--output_dir`. (defaults to `gg_hf`)\n",
    "```\n",
    "python tools/gemma/export_gemma_to_hf.py \\\n",
    "  --weights_file fine_tuned_imdb.weights.h5 \\\n",
    "  --size 2b \\\n",
    "  --vocab_path gemma_lm_tokenizer/vocabulary.spm \\\n",
    "  --output_dir fine_tuned_gg_hf\n",
    "```\n",
    "\n",
    "For converting a Keras model to HuggingFace format from a preset,\n",
    "simply pass the Keras preset name to `--preset` and its model size\n",
    "(`2b` or `7b`) to `--size`.\n",
    "```\n",
    "python tools/gemma/export_gemma_to_hf.py \\\n",
    "    --preset gemma_2b_en \\\n",
    "    --size 2b \\\n",
    "    --output_dir keras_hf_model/\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PRESET_MAP = {\n",
    "    \"gemma_2b_en\": \"gg-hf/gemma-2b\",\n",
    "    \"gemma_instruct_2b_en\": \"gg-hf/gemma-2b\",\n",
    "    \"gemma_7b_en\": \"gg-hf/gemma-7b\",\n",
    "    \"gemma_instruct_7b_en\": \"gg-hf/gemma-7b\",\n",
    "}\n",
    "\n",
    "SIZE_MAP = {\n",
    "    \"2b\": (\"gg-hf/gemma-2b\", \"gemma_2b_en\"),\n",
    "    \"7b\": (\"gg-hf/gemma-7b\", \"gemma_7b_en\"),\n",
    "}\n",
    "\n",
    "gemma_2b_config = transformers.GemmaConfig(\n",
    "    num_hidden_layers=18,\n",
    "    num_attention_heads=8,\n",
    "    num_key_value_heads=1,\n",
    "    hidden_size=2048,\n",
    "    intermediate_size=16384,\n",
    ")\n",
    "\n",
    "gemma_7b_config = transformers.GemmaConfig()\n",
    "\n",
    "CONFIG_MAPPING = {\"2b\": gemma_2b_config, \"7b\": gemma_7b_config}\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string(\n",
    "    \"hf_token\",\n",
    "    None,\n",
    "    \"Your HuggingFace token. Needed for access to the HuggingFace Gemma\"\n",
    "    \"implementation since the repository is private, for now.\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"preset\",\n",
    "    None,\n",
    "    f'Must be one of {\",\".join(PRESET_MAP.keys())}'\n",
    "    \" Alternatively, a Keras weights file (`.weights.h5`) can be passed\"\n",
    "    \" to --weights_file flag.\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"weights_file\",\n",
    "    None,\n",
    "    \"A Keras weights file (`.weights.h5`).\"\n",
    "    \" Alternatively, a model preset can be passed to --preset flag.\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"size\",\n",
    "    None,\n",
    "    \"Size of model. Must be passed if `weights_file` is passed. \"\n",
    "    \"This should be either `2b` or `7b`.\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\",\n",
    "    \"gg_hf\",\n",
    "    \"An output directory for the converted HuggingFace model and tokenizer.\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"vocab_path\",\n",
    "    None,\n",
    "    \"A path containing the vocabulary (must be a `.spm` file or equivalent). \"\n",
    "    \"If not passed, the vocabulary of the preset will be used.\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"dtype\",\n",
    "    \"float32\",\n",
    "    \"Set the precision of the converted checkpoint. Must be a valid PyTorch dtype.\",\n",
    ")\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "    torch.set_default_dtype(dtype)\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)\n",
    "\n",
    "\n",
    "def convert_checkpoints(preset, weights_file, size, output_dir, vocab_path):\n",
    "    if preset is not None:\n",
    "        hf_id = PRESET_MAP[preset]\n",
    "        print(f\"\\n-> Loading KerasNLP Gemma model with preset `{preset}`...\")\n",
    "        keras_nlp_model = keras_nlp.models.GemmaCausalLM.from_preset(preset)\n",
    "    else:\n",
    "        hf_id, keras_preset = SIZE_MAP[size.lower()]\n",
    "        print(f\"\\n-> Loading Keras weights from file `{weights_file}`...\")\n",
    "        keras_nlp_model = keras_nlp.models.GemmaCausalLM.from_preset(\n",
    "            keras_preset\n",
    "        )\n",
    "        keras_nlp_model.load_weights(weights_file)\n",
    "\n",
    "    print(f\"\\n-> Loading HuggingFace Gemma `{size.upper()}` model...\")\n",
    "    hf_model = transformers.GemmaForCausalLM(CONFIG_MAPPING[size.lower()])\n",
    "\n",
    "    print(\"\\n✅ Model loading complete.\")\n",
    "    print(\"\\n-> Converting weights from KerasNLP Gemma to HuggingFace Gemma...\")\n",
    "\n",
    "    # Token embedding (with vocab size difference handling)\n",
    "    keras_embedding = keras_nlp_model.backbone.token_embedding.weights[0]\n",
    "    hf_vocab_size = hf_model.model.embed_tokens.weight.shape[0]\n",
    "    keras_nlp_vocab_size = keras_embedding.value.shape[0]\n",
    "    if hf_vocab_size < keras_nlp_vocab_size:\n",
    "        diff = keras_nlp_vocab_size - hf_vocab_size\n",
    "        update_state_dict(\n",
    "            hf_model.model.embed_tokens,\n",
    "            \"weight\",\n",
    "            keras_embedding.value[:-diff, :],\n",
    "        )\n",
    "    else:\n",
    "        update_state_dict(\n",
    "            hf_model.model.embed_tokens,\n",
    "            \"weight\",\n",
    "            keras_embedding.value,\n",
    "        )\n",
    "\n",
    "    # Decoder blocks\n",
    "    for i in range(keras_nlp_model.backbone.num_layers):\n",
    "        decoder_block = keras_nlp_model.backbone.get_layer(f\"decoder_block_{i}\")\n",
    "\n",
    "        # Pre-attention norm\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].input_layernorm,\n",
    "            \"weight\",\n",
    "            decoder_block.pre_attention_norm.weights[0].value,\n",
    "        )\n",
    "\n",
    "        # Attention\n",
    "        query_target_shape = hf_model.model.layers[\n",
    "            i\n",
    "        ].self_attn.q_proj.weight.shape\n",
    "        query_tensor = decoder_block.attention.query_dense.weights[0].value\n",
    "        query_tensor = query_tensor.transpose(1, 2).reshape(query_target_shape)\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].self_attn.q_proj, \"weight\", query_tensor\n",
    "        )\n",
    "\n",
    "        key_target_shape = hf_model.model.layers[\n",
    "            i\n",
    "        ].self_attn.k_proj.weight.shape\n",
    "        key_tensor = decoder_block.attention.key_dense.weights[0].value\n",
    "        key_tensor = key_tensor.transpose(1, 2).reshape(key_target_shape)\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].self_attn.k_proj, \"weight\", key_tensor\n",
    "        )\n",
    "\n",
    "        value_target_shape = hf_model.model.layers[\n",
    "            i\n",
    "        ].self_attn.v_proj.weight.shape\n",
    "        value_tensor = decoder_block.attention.value_dense.weights[0].value\n",
    "        value_tensor = value_tensor.transpose(1, 2).reshape(value_target_shape)\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].self_attn.v_proj, \"weight\", value_tensor\n",
    "        )\n",
    "\n",
    "        out_target_shape = hf_model.model.layers[\n",
    "            i\n",
    "        ].self_attn.o_proj.weight.shape\n",
    "        keras_out_tensor = decoder_block.attention.output_dense.weights[0].value\n",
    "        out_tensor = keras_out_tensor.reshape(\n",
    "            (out_target_shape[1], out_target_shape[0])  # Transpose target size\n",
    "        ).transpose(0, 1)\n",
    "\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].self_attn.o_proj, \"weight\", out_tensor\n",
    "        )\n",
    "\n",
    "        # Post-attention norm\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].post_attention_layernorm,\n",
    "            \"weight\",\n",
    "            decoder_block.pre_ffw_norm.weights[0].value,\n",
    "        )\n",
    "\n",
    "        # MLP (Feed-forward)\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].mlp.gate_proj,\n",
    "            \"weight\",\n",
    "            decoder_block.gating_ffw.weights[0].value.transpose(0, 1),\n",
    "        )\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].mlp.up_proj,\n",
    "            \"weight\",\n",
    "            decoder_block.gating_ffw_2.weights[0].value.transpose(0, 1),\n",
    "        )\n",
    "        update_state_dict(\n",
    "            hf_model.model.layers[i].mlp.down_proj,\n",
    "            \"weight\",\n",
    "            decoder_block.ffw_linear.weights[0].value.transpose(0, 1),\n",
    "        )\n",
    "\n",
    "    # Final norm\n",
    "    update_state_dict(\n",
    "        hf_model.model.norm,\n",
    "        \"weight\",\n",
    "        keras_nlp_model.backbone.layers[-1].weights[0].value,\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ Weights converted successfully.\")\n",
    "    print(f\"\\n-> Saving HuggingFace model to `{output_dir}`...\")\n",
    "\n",
    "    # Save model to HF Transformers format\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    hf_model.save_pretrained(output_dir)\n",
    "\n",
    "    print(f\"\\n✅ Saving complete. Model saved at `{output_dir}`.\")\n",
    "\n",
    "    # Tokenizer\n",
    "\n",
    "    if not vocab_path:\n",
    "        tokenizer_preset = preset or SIZE_MAP[size.lower()]\n",
    "        print(\n",
    "            \"\\n-> Loading KerasNLP Gemma tokenizer with \"\n",
    "            f\"preset `{tokenizer_preset}`...\"\n",
    "        )\n",
    "        keras_nlp_tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(\n",
    "            tokenizer_preset\n",
    "        )\n",
    "        # Save tokenizer state\n",
    "        keras_nlp_tokenizer.save_assets(output_dir)\n",
    "        vocab_path = os.path.join(output_dir, \"vocabulary.spm\")\n",
    "        print(\"\\n✅ Tokenizer loading complete.\")\n",
    "\n",
    "    hf_tokenizer = transformers.GemmaTokenizer(vocab_path)\n",
    "\n",
    "    print(f\"\\n-> Saving HuggingFace Gemma tokenizer to `{output_dir}`...\")\n",
    "    # Save tokenizer to HF Transformers format\n",
    "    hf_tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    print(f\"\\n✅ Saving complete. Tokenizer saved at `{output_dir}`.\")\n",
    "\n",
    "\n",
    "def update_state_dict(layer, weight_name: str, tensor: torch.Tensor) -> None:\n",
    "    \"\"\"Updates the state dict for a weight given a tensor.\"\"\"\n",
    "    assert (\n",
    "        tensor.shape == layer.state_dict()[weight_name].shape\n",
    "    ), f\"{tensor.shape} vs {layer.state_dict()[weight_name].shape}\"\n",
    "    layer.state_dict()[weight_name].copy_(tensor)\n",
    "\n",
    "\n",
    "def flag_error_handler():\n",
    "    if not FLAGS.preset and not FLAGS.weights_file:\n",
    "        raise ValueError(\n",
    "            \"Please pass either a valid Keras preset to `--preset`\"\n",
    "            \" or supply a Keras weights file (`.weights.h5`) and model size\"\n",
    "            \" (`2b` or `7b`) to `--weights_file` and `--size`, respectively.\"\n",
    "        )\n",
    "    if FLAGS.weights_file:\n",
    "        if FLAGS.preset:\n",
    "            raise ValueError(\n",
    "                \"Both `--preset` and `--weights_file` flags cannot be supplied \"\n",
    "                \"at the same time. Either supply a valid Keras preset to \"\n",
    "                \"`--preset`or supply a Keras `.weights.h5` file and \"\n",
    "                \"model size (`2b` or `7b`) to `--weights_file` and `--size`, \"\n",
    "                \"respectively.\"\n",
    "            )\n",
    "        if not str(FLAGS.weights_file).endswith(\".weights.h5\"):\n",
    "            raise ValueError(\n",
    "                \"Please pass a valid Keras weights file ending in `.weights.h5`.\"\n",
    "            )\n",
    "        if not FLAGS.size:\n",
    "            raise ValueError(\n",
    "                \"The `size` flag must be passed if a weights file is passed. \"\n",
    "                \"Please pass the appropriate size (`2b` or `7b`) for your \"\n",
    "                \"model to the `--size` flag.\"\n",
    "            )\n",
    "        if FLAGS.size.lower() not in [\"2b\", \"7b\"]:\n",
    "            raise ValueError(\n",
    "                \"Invalid `size`. Please pass the appropriate size (`2b` or `7b`) \"\n",
    "                \"for your model to the `--size` flag.\"\n",
    "            )\n",
    "    if FLAGS.dtype:\n",
    "        dtype = getattr(torch, FLAGS.dtype)\n",
    "        if not isinstance(dtype, torch.dtype):\n",
    "            raise ValueError(\n",
    "                \"Invalid `dtype`. Please pass a valid PyTorch data type (e.g. \"\n",
    "                \"`float32', 'float16`, etc.) to the `--dtype` flag.\"\n",
    "            )\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    flag_error_handler()\n",
    "    with _set_default_tensor_type(getattr(torch, FLAGS.dtype)):\n",
    "        convert_checkpoints(\n",
    "            FLAGS.\n",
    "            FLAGS.preset,\n",
    "            FLAGS.weights_file,\n",
    "            FLAGS.size,\n",
    "            FLAGS.output_dir,\n",
    "            FLAGS.vocab_path,\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flags.mark_flag_as_required(\"size\")\n",
    "    app.run(main)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m116"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
