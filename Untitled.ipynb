{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ddc1df0-4802-490c-8867-b5afb94a199c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "from google.cloud import aiplatform, language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00599a98-5b47-444d-8662-0207da36f9a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "# Cloud project id.\n",
    "PROJECT_ID = \"sbx-196865-genaift-ds-ccd784e6\"  # @param {type:\"string\"}\n",
    "\n",
    "# The Hugging Face User Access Token.\n",
    "HF_TOKEN = \"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\"  # @param {type:\"string\"}\n",
    "\n",
    "# Region for launching jobs.\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Cloud Storage bucket for storing experiments output.\n",
    "# Start with gs:// prefix, e.g. gs://foo_bucket.\n",
    "BUCKET_URI = \"gs://19865_finetuned_models\"  # @param {type:\"string\"}\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "! gcloud services enable language.googleapis.com\n",
    "\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
    "EXPERIMENT_BUCKET = os.path.join(BUCKET_URI, \"peft\")\n",
    "MODEL_BUCKET = os.path.join(BUCKET_URI, \"model\")\n",
    "\n",
    "# The service account looks like:\n",
    "# '@.iam.gserviceaccount.com'\n",
    "# Please go to https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console\n",
    "# and create service account with `Vertex AI User` and `Storage Object Admin` roles.\n",
    "# The service account for deploying fine tuned model.\n",
    "SERVICE_ACCOUNT = \"sa-196865-big-data@sbx-196865-genaift-ds-ccd784e6.iam.gserviceaccount.com\"  # @param {type:\"string\"}\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user(project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae38b0e-6e50-4877-8e73-b9e62a522aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = \"google/gemma-7b-it\"\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5578dd-e836-48c4-b757-dd18b5a10c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The pre-built training and serving docker images.\n",
    "TRAIN_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-peft-train:20240220_0936_RC01\"\n",
    "TGI_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-hf-tgi-serve:20240220_0936_RC01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab41b0c3-1747-4b3d-a697-5de548f55a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_job_name_with_datetime(prefix: str) -> str:\n",
    "    \"\"\"Gets the job name with date time when triggering training or deployment\n",
    "    jobs in Vertex AI.\n",
    "    \"\"\"\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def moderate_text(text: str) -> language.ModerateTextResponse:\n",
    "    \"\"\"Calls Vertex AI APIs to analyze text moderations.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "    document = language.Document(\n",
    "        content=text,\n",
    "        type_=language.Document.Type.PLAIN_TEXT,\n",
    "    )\n",
    "    return client.moderate_text(document=document)\n",
    "\n",
    "\n",
    "def show_text_moderation(text: str, response: language.ModerateTextResponse) -> None:\n",
    "    \"\"\"Shows text moderation results.\"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    def confidence(category: language.ClassificationCategory) -> float:\n",
    "        return category.confidence\n",
    "\n",
    "    columns = [\"category\", \"confidence\"]\n",
    "    categories = sorted(response.moderation_categories, key=confidence, reverse=True)\n",
    "    data = ((category.name, category.confidence) for category in categories)\n",
    "    df = pd.DataFrame(columns=columns, data=data)\n",
    "\n",
    "    print(f\"Text analyzed:\\n{text}\")\n",
    "    print(df.to_markdown(index=False, tablefmt=\"presto\", floatfmt=\".0%\"))\n",
    "\n",
    "\n",
    "def deploy_model_tgi(\n",
    "    model_name: str,\n",
    "    model_id: str,\n",
    "    service_account: str,\n",
    "    machine_type: str = \"g2-standard-8\",\n",
    "    accelerator_type: str = \"NVIDIA_L4\",\n",
    "    accelerator_count: int = 1,\n",
    "    max_input_length: int = 512,\n",
    "    max_total_tokens: int = 2048,\n",
    "    max_batch_prefill_tokens: int = 2048,\n",
    ") -> Tuple[aiplatform.Model, aiplatform.Endpoint]:\n",
    "    \"\"\"Deploys models with TGI on GPU in Vertex AI.\"\"\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
    "\n",
    "    env_vars = {\n",
    "        \"MODEL_ID\": model_id,\n",
    "        \"NUM_SHARD\": f\"{accelerator_count}\",\n",
    "        \"MAX_INPUT_LENGTH\": f\"{max_input_length}\",\n",
    "        \"MAX_TOTAL_TOKENS\": f\"{max_total_tokens}\",\n",
    "        \"MAX_BATCH_PREFILL_TOKENS\": f\"{max_batch_prefill_tokens}\",\n",
    "    }\n",
    "\n",
    "    if HF_TOKEN:\n",
    "        env_vars[\"HUGGING_FACE_HUB_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_name,\n",
    "        serving_container_image_uri=TGI_DOCKER_URI,\n",
    "        serving_container_ports=[80],\n",
    "        serving_container_environment_variables=env_vars,\n",
    "        serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n",
    "    )\n",
    "\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        deploy_request_timeout=1800,\n",
    "        service_account=service_account,\n",
    "    )\n",
    "    return model, endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7470816e-9a6d-4257-b08e-1529fcbda2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Huggingface dataset name or gs:// URI to a custom JSONL dataset.\n",
    "dataset_name = \"gs://19865_finetuned_models/training_data/data.jsonl\"  # @param {type:\"string\"}\n",
    "# Name of the dataset column containing training text input.\n",
    "instruct_column_in_dataset = \"text\"  # @param {type:\"string\"}\n",
    "# Optional. Template name or gs:// URI to a custom template.\n",
    "template = \"\"  # @param {type:\"string\"}\n",
    "# Batch size for finetuning.\n",
    "per_device_train_batch_size = 1  # @param{type:\"integer\"}\n",
    "# Runs 10 training steps as a minimal example.\n",
    "max_steps = 10  # @param {type:\"integer\"}\n",
    "# Precision mode for finetuning.\n",
    "finetuning_precision_mode = \"float16\"  # @param[\"4bit\", \"8bit\", \"float16\"]\n",
    "\n",
    "# Worker pool spec.\n",
    "\n",
    "# Finetunes Gemma with 1 L4 (24G).\n",
    "# machine_type = \"g2-standard-8\"\n",
    "# accelerator_type = \"NVIDIA_L4\"\n",
    "# accelerator_count = 1\n",
    "# Finetunes Gemma with 1 V100 (16G).\n",
    "machine_type = \"n1-standard-8\"\n",
    "accelerator_type = \"NVIDIA_TESLA_V100\"\n",
    "accelerator_count = 1\n",
    "\n",
    "replica_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d08f00dc-7230-4694-aab7-e04a9ede223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Output directory:\n",
      "gs://19865_finetuned_models/temporal/aiplatform-custom-training-2024-03-07-11:35:09.404 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7029453745071063040?project=81995035742\n",
      "CustomContainerTrainingJob projects/81995035742/locations/us-central1/trainingPipelines/7029453745071063040 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4893157627883683840?project=81995035742\n",
      "CustomContainerTrainingJob projects/81995035742/locations/us-central1/trainingPipelines/7029453745071063040 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/81995035742/locations/us-central1/trainingPipelines/7029453745071063040 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/81995035742/locations/us-central1/trainingPipelines/7029453745071063040 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/81995035742/locations/us-central1/trainingPipelines/7029453745071063040 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/81995035742/locations/us-central1/trainingPipelines/7029453745071063040 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Training failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=81995035742&resource=ml_job%2Fjob_id%2F4893157627883683840&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%224893157627883683840%22\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m merged_model_dir \u001b[38;5;241m=\u001b[39m get_job_name_with_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma-merged-model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m merged_model_output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_BUCKET, merged_model_dir)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrain_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--task=instruct-lora\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--pretrained_model_id=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_model\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--dataset_name=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--instruct_column_in_dataset=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minstruct_column_in_dataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--output_dir=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlora_output_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--merge_base_and_lora_output_dir=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmerged_model_output_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--per_device_train_batch_size=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--lora_rank=16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--lora_alpha=64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--lora_dropout=0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--max_steps=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmax_steps\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--max_seq_length=512\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--learning_rate=2e-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--precision_mode=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfinetuning_precision_mode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--template=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtemplate\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--huggingface_access_token=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mHF_TOKEN\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWANDB_DISABLED\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmachine_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboot_disk_size_gb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSERVICE_ACCOUNT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoRA adapter was saved in: \u001b[39m\u001b[38;5;124m\"\u001b[39m, lora_output_dir)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained and merged models were saved in: \u001b[39m\u001b[38;5;124m\"\u001b[39m, merged_model_output_dir)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:4630\u001b[0m, in \u001b[0;36mCustomContainerTrainingJob.run\u001b[0;34m(self, dataset, annotation_schema_uri, model_display_name, model_labels, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, base_output_dir, service_account, network, bigquery_destination, args, environment_variables, replica_count, machine_type, accelerator_type, accelerator_count, boot_disk_type, boot_disk_size_gb, reduction_server_replica_count, reduction_server_machine_type, reduction_server_container_uri, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, timeout, restart_job_on_worker_restart, enable_web_access, enable_dashboard_access, tensorboard, sync, create_request_timeout, disable_retries)\u001b[0m\n\u001b[1;32m   4615\u001b[0m service_account \u001b[38;5;241m=\u001b[39m service_account \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mservice_account\n\u001b[1;32m   4617\u001b[0m worker_pool_specs, managed_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_and_validate_run(\n\u001b[1;32m   4618\u001b[0m     model_display_name\u001b[38;5;241m=\u001b[39mmodel_display_name,\n\u001b[1;32m   4619\u001b[0m     model_labels\u001b[38;5;241m=\u001b[39mmodel_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4627\u001b[0m     reduction_server_machine_type\u001b[38;5;241m=\u001b[39mreduction_server_machine_type,\n\u001b[1;32m   4628\u001b[0m )\n\u001b[0;32m-> 4630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotation_schema_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation_schema_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker_pool_specs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker_pool_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanaged_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanaged_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_default_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_default_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4640\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4641\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbigquery_destination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbigquery_destination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_filter_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_filter_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_filter_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_filter_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_filter_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_filter_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestart_job_on_worker_restart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestart_job_on_worker_restart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4656\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_web_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_web_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4657\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_dashboard_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_dashboard_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduction_server_container_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction_server_container_uri\u001b[49m\n\u001b[1;32m   4660\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduction_server_replica_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m   4661\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4662\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4665\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:817\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    816\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    820\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:5336\u001b[0m, in \u001b[0;36mCustomContainerTrainingJob._run\u001b[0;34m(self, dataset, annotation_schema_uri, worker_pool_specs, managed_model, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, args, environment_variables, base_output_dir, service_account, network, bigquery_destination, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, timeout, restart_job_on_worker_restart, enable_web_access, enable_dashboard_access, tensorboard, reduction_server_container_uri, sync, create_request_timeout, block, disable_retries)\u001b[0m\n\u001b[1;32m   5315\u001b[0m             spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontainerSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5316\u001b[0m                 {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value}\n\u001b[1;32m   5317\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m environment_variables\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   5318\u001b[0m             ]\n\u001b[1;32m   5320\u001b[0m (\n\u001b[1;32m   5321\u001b[0m     training_task_inputs,\n\u001b[1;32m   5322\u001b[0m     base_output_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5333\u001b[0m     disable_retries\u001b[38;5;241m=\u001b[39mdisable_retries,\n\u001b[1;32m   5334\u001b[0m )\n\u001b[0;32m-> 5336\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_task_definition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefinition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_task_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_task_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotation_schema_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation_schema_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_filter_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_filter_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_filter_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_filter_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_filter_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_filter_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanaged_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_default_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_default_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcs_destination_uri_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbigquery_destination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbigquery_destination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:830\u001b[0m, in \u001b[0;36m_TrainingJob._run_job\u001b[0;34m(self, training_task_definition, training_task_inputs, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, annotation_schema_uri, model, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, gcs_destination_uri_prefix, bigquery_destination, create_request_timeout, block)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m training_pipeline\n\u001b[1;32m    828\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mView Training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dashboard_uri())\n\u001b[0;32m--> 830\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining did not produce a Managed Model returning None. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    835\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_upload_fail_string\n\u001b[1;32m    836\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:918\u001b[0m, in \u001b[0;36m_TrainingJob._get_model\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to get and instantiate the Model to Upload.\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    RuntimeError: If Training failed.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_failed:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    922\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed. No model available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    923\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:961\u001b[0m, in \u001b[0;36m_TrainingJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_callback()\n\u001b[1;32m    959\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(_JOB_WAIT_TIME)\n\u001b[0;32m--> 961\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mmodel_to_upload \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_failed:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:978\u001b[0m, in \u001b[0;36m_TrainingJob._raise_failure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to raise failure if TrainingPipeline fails.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m    RuntimeError: If training failed.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m code_pb2\u001b[38;5;241m.\u001b[39mOK:\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining failed with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39merror)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Training failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=81995035742&resource=ml_job%2Fjob_id%2F4893157627883683840&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%224893157627883683840%22\"\n"
     ]
    }
   ],
   "source": [
    "# Setup training job.\n",
    "job_name = get_job_name_with_datetime(\"gemma-lora-train\")\n",
    "\n",
    "# Pass training arguments and launch job.\n",
    "train_job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=job_name,\n",
    "    container_uri=TRAIN_DOCKER_URI,\n",
    ")\n",
    "\n",
    "# Create a GCS folder to store the LORA adapter.\n",
    "lora_adapter_dir = get_job_name_with_datetime(\"gemma-lora-adapter\")\n",
    "lora_output_dir = os.path.join(MODEL_BUCKET, lora_adapter_dir)\n",
    "\n",
    "# Create a GCS folder to store the merged model with the base model and the\n",
    "# finetuned LORA adapter.\n",
    "merged_model_dir = get_job_name_with_datetime(\"gemma-merged-model\")\n",
    "merged_model_output_dir = os.path.join(MODEL_BUCKET, merged_model_dir)\n",
    "\n",
    "train_job.run(\n",
    "    args=[\n",
    "        \"--task=instruct-lora\",\n",
    "        f\"--pretrained_model_id={base_model}\",\n",
    "        f\"--dataset_name={dataset_name}\",\n",
    "        f\"--instruct_column_in_dataset={instruct_column_in_dataset}\",\n",
    "        f\"--output_dir={lora_output_dir}\",\n",
    "        f\"--merge_base_and_lora_output_dir={merged_model_output_dir}\",\n",
    "        f\"--per_device_train_batch_size={per_device_train_batch_size}\",\n",
    "        \"--lora_rank=16\",\n",
    "        \"--lora_alpha=64\",\n",
    "        \"--lora_dropout=0.1\",\n",
    "        f\"--max_steps={max_steps}\",\n",
    "        \"--max_seq_length=512\",\n",
    "        \"--learning_rate=2e-4\",\n",
    "        f\"--precision_mode={finetuning_precision_mode}\",\n",
    "        f\"--template={template}\",\n",
    "        f\"--huggingface_access_token={HF_TOKEN}\",\n",
    "    ],\n",
    "    environment_variables={\"WANDB_DISABLED\": True},\n",
    "    replica_count=replica_count,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    boot_disk_size_gb=500,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")\n",
    "\n",
    "print(\"LoRA adapter was saved in: \", lora_output_dir)\n",
    "print(\"Trained and merged models were saved in: \", merged_model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbadcbb-c991-48b7-9719-21373bff93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_type = \"g2-standard-8\"\n",
    "accelerator_type = \"NVIDIA_L4\"\n",
    "accelerator_count = 1\n",
    "\n",
    "# Note that larger token counts will require more GPU memory.\n",
    "max_input_length = 512\n",
    "max_total_tokens = 1024\n",
    "max_batch_prefill_tokens = 2048\n",
    "\n",
    "model, endpoint = deploy_model_tgi(\n",
    "    model_name=get_job_name_with_datetime(prefix=\"gemma-tgi-serve\"),\n",
    "    model_id=merged_model_output_dir,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    max_input_length=max_input_length,\n",
    "    max_total_tokens=max_total_tokens,\n",
    "    max_batch_prefill_tokens=max_batch_prefill_tokens,\n",
    ")\n",
    "print(\"endpoint_name:\", endpoint.name)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m116"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
